{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fa044a-b7bc-4acc-ab1f-562a68b9bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70083059-0937-4e95-acd1-3d52d3ab7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer,RegexpStemmer\n",
    "\n",
    "#Re: Spacy abridged words and biagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f2c383-e2d5-4bf7-8638-8612199f57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"C:/Users/Hp Pc/Downloads/Books_small_10000.json\"\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append((review['reviewText'], review['overall']))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34f79a40-b187-4f86-859c-e2aee1e2a9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with.\",\n",
       " 5.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca37ea-6dac-46a8-acdf-767e0d78763f",
   "metadata": {},
   "source": [
    "STEMMING/LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dff9465-2ebd-488b-88d6-16d1af82c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b2a7b37-bf83-4a54-bff0-9ee015e1e1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Hp\n",
      "[nltk_data]     Pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7948134c-88fe-4303-836d-96876e3c4c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"\"\"Caressing her bodies fairly' temprature' goes habitaing \"\"\"\n",
    "\n",
    "tokens = word_tokenize(phrase)\n",
    "p_tokens = wordpunct_tokenize(phrase)\n",
    "\n",
    "P_stem = [stemmer.stem(word) for word in p_tokens]\n",
    "\n",
    "stem = [stemmer.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d44645-a5d3-40b3-89f9-01886d9d1d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caress', 'her', 'bodi', 'fairli', \"'\", 'tempratur', \"'\", 'goe', 'habita']\n",
      "['caress', 'her', 'bodi', 'fairli', \"'\", 'tempratur', \"'\", 'goe', 'habita']\n"
     ]
    }
   ],
   "source": [
    "print(P_stem)\n",
    "print(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f86f94-9ac2-404d-a026-058b4ef03327",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stemmer = SnowballStemmer('english')\n",
    "\n",
    "tokens = word_tokenize(phrase)\n",
    "\n",
    "s_stem = [s_stemmer.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a2bf76b-562a-453b-97c0-e8ebb67fee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['caress', 'her', 'bodi', 'fair', \"'\", 'tempratur', \"'\", 'goe', 'habita']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7199b648-41c6-489b-9b6a-b11a6c4304ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4) #regex condition can be changed to different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a5bdf28-5682-4a56-ba29-0b3af380bdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Caress', 'her', 'bodie', 'fairly', \"'\", 'tempratur', \"'\", 'goe', 'habita']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_st = [regex_stemmer.stem(word) for word in tokens]\n",
    "re_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a95ea4-2aa0-488f-898b-4d88be46572e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe4f6ad-5423-4790-b1d4-fb12034913db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Hp\n",
      "[nltk_data]     Pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Hp\n",
      "[nltk_data]     Pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beb610c4-105e-4585-aa65-21d742d22c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'run', 'run', 'easily', 'fairly', 'best', 'better', 'goodness', 'worst', 'worse']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = [\"running\", \"ran\", \"runs\", \"easily\", \"fairly\",'best', 'better', 'goodness', 'worst', 'worse']\n",
    "\n",
    "\n",
    "lemm_words = [lemmatizer.lemmatize(word,pos='v') for word in words]\n",
    "\n",
    "print(lemm_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70193c64-b168-42fd-a6cb-b328aa70f779",
   "metadata": {},
   "source": [
    "STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b61020f-6690-4f8c-81e2-872167048845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5651be0-d93e-43c1-90a5-bb96adf1475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Hp\n",
      "[nltk_data]     Pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41c82742-4314-482a-a294-8159883151c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cd64060-15c9-4dcd-bae7-8571706c38c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "487b6923-db32-45a3-bf34-1d1c2eb17c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_tokens = word_tokenize(reviews[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13d710c4-594c-44bb-9ae4-3b4268530eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'bought',\n",
       " 'both',\n",
       " 'boxed',\n",
       " 'sets',\n",
       " ',',\n",
       " 'books',\n",
       " '1-5',\n",
       " '.',\n",
       " 'Really',\n",
       " 'a',\n",
       " 'great',\n",
       " 'series',\n",
       " '!',\n",
       " 'Start',\n",
       " 'book',\n",
       " '1',\n",
       " 'three',\n",
       " 'weeks',\n",
       " 'ago',\n",
       " 'and',\n",
       " 'just',\n",
       " 'finished',\n",
       " 'book',\n",
       " '5',\n",
       " '.',\n",
       " 'Sloane',\n",
       " 'Monroe',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'character',\n",
       " 'and',\n",
       " 'being',\n",
       " 'able',\n",
       " 'to',\n",
       " 'follow',\n",
       " 'her',\n",
       " 'through',\n",
       " 'both',\n",
       " 'private',\n",
       " 'life',\n",
       " 'and',\n",
       " 'her',\n",
       " 'PI',\n",
       " 'life',\n",
       " 'gets',\n",
       " 'a',\n",
       " 'reader',\n",
       " 'very',\n",
       " 'involved',\n",
       " '!',\n",
       " 'Although',\n",
       " 'clues',\n",
       " 'may',\n",
       " 'be',\n",
       " 'right',\n",
       " 'in',\n",
       " 'front',\n",
       " 'of',\n",
       " 'the',\n",
       " 'reader',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'twists',\n",
       " 'and',\n",
       " 'turns',\n",
       " 'that',\n",
       " 'keep',\n",
       " 'one',\n",
       " 'guessing',\n",
       " 'until',\n",
       " 'the',\n",
       " 'last',\n",
       " 'page',\n",
       " '!',\n",
       " 'These',\n",
       " 'are',\n",
       " 'books',\n",
       " 'you',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'be',\n",
       " 'disappointed',\n",
       " 'with',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de6e8c5a-182c-48d8-9d31-e9a0319935e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "bought\n",
      "boxed\n",
      "sets\n",
      ",\n",
      "books\n",
      "1-5\n",
      ".\n",
      "Really\n",
      "great\n",
      "series\n",
      "!\n",
      "Start\n",
      "book\n",
      "1\n",
      "three\n",
      "weeks\n",
      "ago\n",
      "finished\n",
      "book\n",
      "5\n",
      ".\n",
      "Sloane\n",
      "Monroe\n",
      "great\n",
      "character\n",
      "able\n",
      "follow\n",
      "private\n",
      "life\n",
      "PI\n",
      "life\n",
      "gets\n",
      "reader\n",
      "involved\n",
      "!\n",
      "Although\n",
      "clues\n",
      "may\n",
      "right\n",
      "front\n",
      "reader\n",
      ",\n",
      "twists\n",
      "turns\n",
      "keep\n",
      "one\n",
      "guessing\n",
      "last\n",
      "page\n",
      "!\n",
      "These\n",
      "books\n",
      "wo\n",
      "n't\n",
      "disappointed\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#filtering with stopwords\n",
    "filter_review = []\n",
    "for word in re_tokens:\n",
    "    if word not in set(stopwords.words('english')):\n",
    "        print(word)\n",
    "        filter_review.append(s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cd275c2-1801-4024-bdf4-e2ba7dfffc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i bought box set , book 1-5 . realli great seri ! start book 1 three week ago finish book 5 . sloan monro great charact abl follow privat life pi life get reader involv ! although clue may right front reader , twist turn keep one guess last page ! these book wo n't disappoint .\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(filter_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5687af3-600b-431b-b19c-1afe90174588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0498fd71-3317-4f99-9cbb-d36c48fbf25a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "bought\n",
      "boxed\n",
      "sets\n",
      ",\n",
      "books\n",
      "1-5\n",
      ".\n",
      "Really\n",
      "great\n",
      "series\n",
      "!\n",
      "Start\n",
      "book\n",
      "1\n",
      "three\n",
      "weeks\n",
      "ago\n",
      "finished\n",
      "book\n",
      "5\n",
      ".\n",
      "Sloane\n",
      "Monroe\n",
      "great\n",
      "character\n",
      "able\n",
      "follow\n",
      "private\n",
      "life\n",
      "PI\n",
      "life\n",
      "gets\n",
      "reader\n",
      "involved\n",
      "!\n",
      "Although\n",
      "clues\n",
      "may\n",
      "right\n",
      "front\n",
      "reader\n",
      ",\n",
      "twists\n",
      "turns\n",
      "keep\n",
      "one\n",
      "guessing\n",
      "last\n",
      "page\n",
      "!\n",
      "These\n",
      "books\n",
      "wo\n",
      "n't\n",
      "disappointed\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "filtered_review = []\n",
    "for word in re_tokens:\n",
    "    if word not in set(stopwords.words('english')):\n",
    "        print(word)\n",
    "        filtered_review.append(lemmatizer.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b91d9ad-f8f4-42ec-9fc0-60f108cedfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I buy box set , book 1-5 . Really great series ! Start book 1 three weeks ago finish book 5 . Sloane Monroe great character able follow private life PI life get reader involve ! Although clue may right front reader , twist turn keep one guess last page ! These book wo n't disappoint .\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(filtered_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81c91dc1-40fd-4c41-861f-31f11389a37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3756ed-fde7-493e-aede-eafc7adad063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c18d611-3f4f-482f-a574-4608e2db0e11",
   "metadata": {},
   "source": [
    "PART_OF_SPEECH TAG (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "707ad391-682a-4191-b9d0-1d81afc7eb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Hp Pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7356bbd-2f65-4c7c-858f-82d27ef8f927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP')]\n",
      "[('bought', 'NN')]\n",
      "[('boxed', 'NN')]\n",
      "[('sets', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('books', 'NNS')]\n",
      "[('1-5', 'JJ')]\n",
      "[('.', '.')]\n",
      "[('Really', 'RB')]\n",
      "[('great', 'JJ')]\n",
      "[('series', 'NN')]\n",
      "[('!', '.')]\n",
      "[('Start', 'NN')]\n",
      "[('book', 'NN')]\n",
      "[('1', 'CD')]\n",
      "[('three', 'CD')]\n",
      "[('weeks', 'NNS')]\n",
      "[('ago', 'RB')]\n",
      "[('finished', 'VBN')]\n",
      "[('book', 'NN')]\n",
      "[('5', 'CD')]\n",
      "[('.', '.')]\n",
      "[('Sloane', 'NN')]\n",
      "[('Monroe', 'NN')]\n",
      "[('great', 'JJ')]\n",
      "[('character', 'NN')]\n",
      "[('able', 'JJ')]\n",
      "[('follow', 'VB')]\n",
      "[('private', 'JJ')]\n",
      "[('life', 'NN')]\n",
      "[('PI', 'NN')]\n",
      "[('life', 'NN')]\n",
      "[('gets', 'VBZ')]\n",
      "[('reader', 'NN')]\n",
      "[('involved', 'VBN')]\n",
      "[('!', '.')]\n",
      "[('Although', 'IN')]\n",
      "[('clues', 'NNS')]\n",
      "[('may', 'MD')]\n",
      "[('right', 'NN')]\n",
      "[('front', 'NN')]\n",
      "[('reader', 'NN')]\n",
      "[(',', ',')]\n",
      "[('twists', 'NNS')]\n",
      "[('turns', 'NNS')]\n",
      "[('keep', 'VB')]\n",
      "[('one', 'CD')]\n",
      "[('guessing', 'VBG')]\n",
      "[('last', 'JJ')]\n",
      "[('page', 'NN')]\n",
      "[('!', '.')]\n",
      "[('These', 'DT')]\n",
      "[('books', 'NNS')]\n",
      "[('wo', 'MD')]\n",
      "[(\"n't\", 'RB')]\n",
      "[('disappointed', 'JJ')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for word in re_tokens:\n",
    "    if word not in set(stopwords.words('english')):\n",
    "        pos_tags = nltk.pos_tag([word])\n",
    "        print(pos_tags)\n",
    "        #nltk.pos_tag(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09c0c629-0473-451d-932a-12ae7a62f804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('enjoyed', 'VBD'), ('short', 'JJ'), ('book', 'NN'), ('.', '.'), ('But', 'CC'), ('way', 'NN'), ('way', 'NN'), ('short', 'JJ'), ('....', 'NN'), ('I', 'PRP'), ('see', 'VBP'), ('easily', 'RB'), ('would', 'MD'), ('add', 'VB'), ('several', 'JJ'), ('chapters', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#for words in re_tokens:\n",
    "re_token = word_tokenize(reviews[1][0])\n",
    "word = [word for word in re_token if word not in set(stopwords.words('english'))]\n",
    "pos_word = nltk.pos_tag(word)\n",
    "print(pos_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cf166-1550-4807-8d8e-7b2d469fc564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2828339-43c7-4cdd-8d02-cef875b8df66",
   "metadata": {},
   "source": [
    "NAMED ENTITY RECOGNITION NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbad4a31-c102-4e7d-831b-11eefacfdd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to C:\\Users\\Hp\n",
      "[nltk_data]     Pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5f696bc-4f15-4c12-9102-b242ac0ec10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\" The Eiffel Tower wa built from 1887 to 1889 by French engineer Gustave Eiffel, whose company specialized\n",
    "in building metal frameworks and structures for a speculated amount of $300 Million\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e56f5fae-f1c6-412c-9a2a-cecc72dcde1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tree.draw of Tree('S', [('The', 'DT'), Tree('ORGANIZATION', [('Eiffel', 'NNP'), ('Tower', 'NNP')]), ('wa', 'NN'), ('built', 'VBN'), ('from', 'IN'), ('1887', 'CD'), ('to', 'TO'), ('1889', 'CD'), ('by', 'IN'), Tree('GPE', [('French', 'JJ')]), ('engineer', 'NN'), Tree('PERSON', [('Gustave', 'NNP'), ('Eiffel', 'NNP')]), (',', ','), ('whose', 'WP$'), ('company', 'NN'), ('specialized', 'VBD'), ('in', 'IN'), ('building', 'NN'), ('metal', 'NN'), ('frameworks', 'NNS'), ('and', 'CC'), ('structures', 'NNS'), ('for', 'IN'), ('a', 'DT'), ('speculated', 'JJ'), ('amount', 'NN'), ('of', 'IN'), ('$', '$'), ('300', 'CD'), ('Million', 'NNP')])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = word_tokenize(sentence)\n",
    "pos_tag = nltk.pos_tag(token)\n",
    "\n",
    "\n",
    "#use nltk_chunker to recognize named entities\n",
    "nltk.ne_chunk(pos_tag).draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14ad9b-68ea-445e-b29e-e9c5bf3a986b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c705d66f-3aa5-4323-a77d-fbf0762e6dca",
   "metadata": {},
   "source": [
    "TEXTBLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8172673-0345-45ab-a180-d10a9d63e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "#using textblob for spelling_correction, Sentiment,Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e9a5360-b821-4553-8b29-3181fce757ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"Exxuse the misstake\"\n",
    "blob_word = TextBlob(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf632108-14fd-4e76-bb63-56777c4f6a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Excuse the mistake\")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_word.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4a41785-a059-4f54-bd25-5a28c1058e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"His function can not recognize some other copies words\")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"This funcction can not recognaiz somm other coples words\"\n",
    "blob_word = TextBlob(word)\n",
    "blob_word.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd56ef02-799e-4513-b7a8-f2b61c8fb7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('funcction', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('recognaiz', 'VB'),\n",
       " ('somm', 'NN'),\n",
       " ('other', 'JJ'),\n",
       " ('coples', 'NNS'),\n",
       " ('words', 'NNS')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_word.tags #parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a41b3a0-73a6-42aa-a5d2-e01ef015ee17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.125, subjectivity=0.375)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_word.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9720a20-992c-4862-80bf-3caccf332302",
   "metadata": {},
   "source": [
    "USING BERT-TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6c57bc9-c6a9-4ab2-ace1-c9640ba9c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52bac3cb-5187-45f4-b5bf-028654a9c659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377e0f746f5e440c823b2617c17de98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  17%|#6        | 73.4M/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d6e9137-1bf3-438d-8e74-b55a4f841686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I enjoyed this short book. But it was way way to short ....I can see how easily it would have been to add several chapters.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91ef6571-cf89-464f-82a0-6da270bd7e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love Nicholas Sparks. I&#8217;ve read everything he&#8217;s written and couldn&#8217;t wait for my copy of Safe Haven to arrive.Safe Haven had a different feel than many of Nicholas Sparks books. It was much less sappy than most of his books. Don&#8217;t get me wrong&#8230; I love sappy but this book was much deeper than many of his other books. It explored life in an abusive relationship and the struggle to escape and start over.I felt a connection to the characters and never lost interest in the story. The audio narration was well done. The only thing that annoyed me was the whiny voice the narrator used for 5 year old Kristen. Fortunately she didn&#8217;t have many lines in the book.This book played out in a predictable manner. Although one thing I have learned from reading Nicholas Sparks is that sometimes he is not predictable and he goes for the heart-break ending. This book did have an unpredictable element to the ending but thankfully it was a touching unpredictable and not a heart-breaking unpredictable.Content: Just a couple of swear words. One of the characters in this book is psycho, I mean seriously crazy. We hear his demented crazy thought process and the details of some of the things he does are described. There are scenes of physical abuse described and a few sex scenes that aren&#8217;t overly graphic but are lewd. Although I can&#8217;t classify this book as clean it wasn&#8217;t nearly as graphic as it could have been. It was well written and I would recommend it to adults who have read this content warning.Rating: 4 Stars. I made it through this book in less than 2 days. Some great writing from Nicholas Sparks.Source: I received an audio version of this book from Hachette.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bd2d557-a741-4ae4-82b7-72c775e100bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_text = reviews[2][0]\n",
    "\n",
    "text_token = tokenizer(bert_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ec2886e-d08f-49a4-bacf-61fc91a21a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**text_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e7404-f244-4133-8dbe-b28440476494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
